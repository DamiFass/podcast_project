{"podcast_details": {"podcast_title": "AI Today Podcast: Artificial Intelligence Insights, Experts, and Opinion", "episode_title": "AI Today Podcast: AI Glossary Series \u2013 Algorithmic Discrimination, Governance, Pseudo AI", "episode_image": "https://www.aidatatoday.com/wp-content/uploads/2023/02/New-AI-Today-Podcast-Image-1.png", "episode_transcript": " The AI Today podcast produced by Cognolitica cuts through the hype and noise to identify what is really happening now in the world of artificial intelligence. Learn about emerging AI trends, technologies, and use cases from Cognolitica analysts and guest experts. Hey AI Today listeners. Want to dive deeper and get resources to drive your AI efforts further? We've put together a carefully curated collection of resources and tools handcrafted for you, our listeners, to expand your knowledge, dive deeper into the world of AI, and provide you with the essential resources you need. From books and materials ranging from fundamentals of AI to deep dives on implementing AI projects to AI ethics, tools, software, checklists, and more, our resources page will help you on your AI journey, whether you're just starting out or you're well on your way. Check it out at aitoday.live slash list. That's a itoday.live slash li st. Hello and welcome to the AI Today podcast. I'm your host Kathleen Mulch. And I'm your host, Ronald Schmelzer. And thanks again. As you know, we've been diving deep into many of the terms that you need to know around AI, machine learning, and big data as part of our glossary series. We have many other podcasts that have talked about our practitioners and what they're doing with AI and being successful in our failure series and our automation to intelligence series and our use case series and so many things. But the reason why we're doing the glossary series is because there's a lot of terms out there that you may have heard that you may or may not know what they mean or you do know what they mean when you want to understand it or maybe there's some confusion or whatever the reason. And that's why we're doing the AI glossary series. And we've had many, many, many podcasts in the series, starting from what is AI to many of the terms around machine learning, a lot of the big data terms and so many other terms, robotics and RPA. But we're going to start, you know, we'll dig into all the different facets and corners of AI so that way all the terms are explained. So if you haven't yet, please do subscribe to AI Today so you can listen not only to this one, but the ones coming up. And of course, listen to our other podcasts that have gone over some of these key terms. Exactly. And the AI glossary is incredibly robust. We linked to it in the show notes. You can also find it at Cognitica.com. But it helps you understand these terms at a high level. Maybe you've never heard of them before. And then we present them on the podcast in groupings that make logical sense. So you kind of understand how everything relates to each other. So in today's podcast, we're going to go over the terms algorithmic discrimination, governance and pseudo AI. Yes. So let's start with algorithmic discrimination. So this idea is that, of course, people have bias and people have their own thoughts about the world, which may not be valid. But we can encode those thoughts and biases in algorithms. So algorithmic discrimination is bias in data that is used to train that we use that data, bias data to train the algorithm that then results in unfair decisions. Because what we're thinking about with discrimination is, of course, not just things happening, decisions being made. It's when they're being made unfairly or for what is perceived as unfairly. And when using algorithms to make decisions, especially the ones that impact humans, such as loan decisions and hiring decisions and all sorts of stuff, when people feel like the algorithm itself is biased in a specific way, that can really hurt. There was a book that came out not too long ago called Weapons of Math Destruction by Cathy O'Neill that really talks about this idea of algorithmic discrimination. And it's a combination of multiple factors. A lot of it's not really necessarily by intent. It's not that people are intentionally creating these systems, but there are flaws in the data. And it's not just the flaws in the data. It's the fact that there's a lot of opacity. These models are not explained. They're not explainable. And sometimes even the people who use them may not know how the decisions are being made. The other thing is that sometimes we put a lot of trust in these algorithms, especially if they're being used for things like content moderation, loan decisions, hiring decisions. And because the human is a little bit out of the loop, these algorithms that do have possible issues can really be hurt at large scale. And that's the other thing. It's not just bad decisions for things like recommending the wrong product to buy. That doesn't have a lot of impact. It's the ones that do have a lot of impact that we're most concerned about, the damage factor. And especially things like loan decisions, as we made before, maybe it was using old data that might have had some issues and bias and possible things that then became part of the model. It could be even things like penalizing employees based on their call history or call record when we may be using call history that may be biased based on different call center reps or the experience or things that are even image recognition, image classification, where the data sets may have over-representation, under-representation, and certain groups may be biased in terms of these different aspects of AI. Exactly. Of course, we're using this word bias multiple ways, right Kathleen? Yes, we are. And so if you've been listening to our glossary series, you know that we have used the word bias for a few different things. We have bias variance trade-off. Now we're having another definition of bias. So definitely listen, sometimes words can have multiple meanings and we know that. But basically with this idea, it's just how do we know that the training data doesn't have any inherent human-caused data biases in this? So what we say is, well, maybe you need to keep humans in the loop so that you can make sure that you're at least having some oversights here. And this kind of brings us to this next term that we want to define, which is governance. And this also falls into our ethical and responsible AI. We had a podcast series on that, which we go over this kind of concept in greater detail as well. But at a high level here, governance is processes and structures for supervision and control of a given system or organization. So specifically for AI, governance refers to the policies, procedures, record-keeping, auditing, controls, measures, guidelines, practices, tools, and systems that ensure proper and compliant functioning of systems according to organizational needs. So every organization will have their own governance structure. You need to set that up. But it's really just, as we mentioned, the policies and procedures, record-keeping, making sure that you have oversights in place because you don't want your data to just be everywhere, have everybody have access to everything. So you need to make sure that you're having some control over it, which is this idea of governance. So as I mentioned, it is really kind of related to this idea of ethical and responsible AI or trustworthy AI, where it's controls, processes, and organizational structures that ensures ethical, responsible, and transparent AI. This is a kind of core concept that's really coming up. People are discussing it more and more, making sure if we are having AI make decisions for us, well, we had just presented on kind of this algorithmic discrimination, what can happen with that. So if we are, the more that it comes into our everyday lives, how are we having this governance in place to really make sure that we have an understanding and oversight of all of this? Yeah, and this sort of brings us to a related concept. These are all related concepts. They're all different concepts. Obviously, we can use governance to address some of the issues of algorithmic discrimination and actually many of the issues of ethical and trustworthy AI. In fact, we have a whole framework of different considerations for ethical and responsible AI and a podcast series where you can listen and hear about all those different aspects of trustworthy and ethical and responsible AI. We will make sure to listen to it. You can listen to the whole series because we dive into all of these concepts in greater detail. There's this other term that we want to explain that is sort of related called pseudo AI. And pseudo AI is this idea of a company or product that claims the use of AI for a given task but is actually using humans to perform those tasks without properly disclosing the use of humans for that task. Now it's kind of interesting because usually it's the opposite where it's like you want to claim that something is not using humans, it's using humans but it's actually using AI. This is actually the reverse. You claim that something is AI but really using humans. And so it's humans that are pretending to be machines that would, of course, be pretending to be humans because it's artificial intelligence. So there are many examples out there. We've cited them in our previous work. And if you go out and you do research, you'll see examples like Expensify using humans to actually do the receipt processing when they said that they were using image recognition or XAI, using humans to schedule a calendar, things when they said that it was going to be an AI system. Now, is this a problem? Well, it is a problem if you're disclosing private information or you don't want a human to be involved and you truly want a machine to be involved. And this is an issue because it violates user trust, especially if it's not being disclosed. You have tons of issues of private information and anonymization and disclosure and all that sort of stuff. You even have situations where Amazon does not disclose that sometimes it's letting humans listen in to the conversations on Alexa. If you knew that, maybe you wouldn't be saying some of the stuff you're saying. Maybe you're joking around, even not realizing that a human might actually be listening without proper disclosures. Now, I'm sure you think they've changed things a little bit to say that it's possible a human might be listening. There's lots of reasons why people may do this. Maybe there's pressure that the AI system doesn't really work that well. They want the AI system to work. So they're kind of covering the gaps with humans. So maybe the humans aren't 100% of the time, but enough. Sometimes they've got investor money and they had to make some claims and they're sort of covering their butt a little bit. But honestly, this is not a good idea. Pseudo-AI is a violation of trust. If you need to have the human in the loop, just disclose it. And you should think about this in terms of augmented intelligence, where an AI system is helping a human do their job better, not in replacement. Because if it can't truly work in replacement, if you can't truly make it work autonomously, then you should think of it as this augmented function. And that'll be better. And of course, be realistic. As we say constantly, one of the main failure modes of AI is over-promising and under-delivering. And pseudo-AI is actually this exact example of over-promising and under-delivering. Yes, it absolutely is. So we hope that you, at least at a high level now, if people talk about algorithmic discrimination, governance, pseudo-AI, you have an understanding of what it is. But of course, understanding these terms at a high level and knowing how to put them into practice are two different things. So if you're interested in learning more about how to put these into practice and understanding how to apply CPM AI methodology, the cognitive project management for AI methodology, then you're in luck because we've created a free intro course for our AI Today listeners. You can go to aitoday.live.cpmai and it'll give you a really good overview of the methodology and how to put it into practice for AI project success. If you'd like to dig a lot deeper into the methodology and become CPM AI certified as well, then I encourage you to go to cognalitica.com.cpmai where you can sign up for the training and upon completion of the training and all of the exercises, you will become CPM AI certified. And then you'll really have a much better and very comprehensive understanding of how to put CPM AI into practice, how to apply it for AI project success. I know that many of our podcast listeners have become CPM AI certified. And so we would love for you to join in on our community that is really growing and it's international as well. So it's been wonderful to see it grow. So I'll link to both of those in the show notes. So you can just click on the link or you can type in the URLs that I shared. Like this episode and want to hear more? With hundreds of episodes and over 3 million downloads, check out more AI Today podcasts at aitoday.live. Make sure to subscribe to AI Today if you haven't already on Apple podcasts, Spotify, Stitcher, Google, Amazon, or your favorite podcast platform. Want to dive deeper and get resources to drive your AI efforts further? We've put together a carefully curated collection of resources and tools, handcrafted for you, our listeners, to expand your knowledge, dive deeper into the world of AI, and provide you with the essential resources you need. Check it out at aitoday.live. This sound recording and its contents are copyright by Cognolitica, all rights reserved. Music by Matsu Gravas. As always, thanks for listening to AI Today and we'll catch you at the next podcast."}, "podcast_summary": "In this episode of the AI Today podcast, the hosts discuss three important topics: algorithmic discrimination, governance, and pseudo-AI. Algorithmic discrimination refers to bias in data used to train algorithms, resulting in unfair decisions. Governance involves the processes and structures for supervision and control of AI systems. Pseudo-AI occurs when companies claim to use AI for a task but actually use humans without proper disclosure. These concepts are essential for ethical and responsible AI implementation. To learn more, listeners can access free resources and training on AI methodology.", "podcast_guest": "Cathy O'Neill", "podcast_highlights": "- Highlight 1: Algorithmic discrimination is bias in data used to train algorithms that results in unfair decisions.\n- Highlight 2: Governance refers to the policies and procedures that ensure proper and compliant functioning of AI systems.\n- Highlight 3: Pseudo-AI is when a company claims to use AI for a task but is actually using humans without proper disclosure."}